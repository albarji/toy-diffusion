{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9887c243",
   "metadata": {},
   "source": [
    "# Toy diffusion model generating data from a complex 1-d distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b284f76",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0311948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "generator = np.random.default_rng(seed=12345)\n",
    "# Uniform numbers over the range [0, 1]\n",
    "#x = generator.uniform(low=0.0, high=1.0, size=100000)\n",
    "x = generator.uniform(low=0.0, high=1.0, size=10000)\n",
    "# Add gaussian centered in 0.2\n",
    "x = np.concatenate([x, generator.normal(0.2, 1, size=10000)])\n",
    "# Add another high variance gaussian centered in 5\n",
    "x = np.concatenate([x, generator.normal(5, 5, size=20000)])\n",
    "# Add another low variance gaussian centered in 15\n",
    "x = np.concatenate([x, generator.normal(15, 1, size=10000)])\n",
    "# Normalize and center\n",
    "x = (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(x, kde=True, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7472c8",
   "metadata": {},
   "source": [
    "## Prepare data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de92ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "\n",
    "X = rearrange(torch.tensor(x, dtype=torch.float32), \"x -> x 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9166d03",
   "metadata": {},
   "source": [
    "## Noising functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e934300",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_steps = 1000\n",
    "\n",
    "s = 0.008\n",
    "timesteps = torch.tensor(range(0, diffusion_steps), dtype=torch.float32)\n",
    "schedule = torch.cos((timesteps / diffusion_steps + s) / (1 + s) * torch.pi / 2)**2\n",
    "\n",
    "baralphas = schedule / schedule[0]\n",
    "betas = 1 - baralphas / torch.concatenate([baralphas[0:1], baralphas[0:-1]])\n",
    "alphas = 1 - betas\n",
    "sigmas = torch.sqrt(betas)\n",
    "\n",
    "sns.lineplot(baralphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55680085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(Xbatch, t):\n",
    "    if torch.is_tensor(t):\n",
    "        t = t.flatten()\n",
    "    eps = torch.randn(size=(len(Xbatch), 1))\n",
    "    noised = rearrange(torch.sqrt(baralphas[t]), \"x -> x 1\") * Xbatch + rearrange(torch.sqrt(1 - baralphas[t]), \"x -> x 1\") * eps\n",
    "    return noised, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816df6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiselevel = 999\n",
    "\n",
    "noised, eps = noise(X, [noiselevel] * len(X))\n",
    "sns.displot(X, kde=True, bins=100)\n",
    "sns.displot(noised, kde=True, bins=100)\n",
    "denoised = 1 / torch.sqrt(baralphas[noiselevel]) * (noised - torch.sqrt(1 - baralphas[noiselevel]) * eps)\n",
    "sns.displot(denoised, kde=True, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X - denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39202a7c",
   "metadata": {},
   "source": [
    "## Diffusion network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe17c88",
   "metadata": {},
   "source": [
    "Denoising model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d045d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        timesteps = torch.randint(0, diffusion_steps, size=[len(Xbatch), 1])\n",
    "        noised, eps = noise(Xbatch, timesteps)\n",
    "        predicted_noise = model(torch.hstack([noised, timesteps]).to(device))\n",
    "        loss = loss_fn(predicted_noise, eps.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss\n",
    "    print(f\"Epoch {epoch} loss = {epoch_loss / i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844512d",
   "metadata": {},
   "source": [
    "Best model (complex problem):\n",
    "* Without t: 0.003909660503268242\n",
    "* With t as a second input: Epoch 99 loss = 0.0016174211632460356"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6c44f",
   "metadata": {},
   "source": [
    "## Test sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, nsamples):\n",
    "    model = model.to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(size=(nsamples, 1))\n",
    "        for t in range(diffusion_steps-1, 0, -1):\n",
    "            predicted_noise = model(torch.hstack([x, torch.ones(size=[nsamples, 1]) * t]))\n",
    "            # Predict x0 using DDPM equations\n",
    "            # x = 1 / torch.sqrt(alphas[t]) * (x - betas[t] / torch.sqrt(1 - baralphas[t]) * predicted_noise)\n",
    "            # x = x - (1 - alphas[t]) / torch.sqrt(1 - baralphas[t]) * predicted_noise\n",
    "            # Predict original sample using DDPM Eq. 15\n",
    "            x0 = (x - (1 - baralphas[t]) ** (0.5) * predicted_noise) / baralphas[t] ** (0.5)\n",
    "            # Predict previous samples using DDPM Eq. 7\n",
    "            c0 = (baralphas[t-1] ** (0.5) * betas[t]) / (1 - baralphas[t])\n",
    "            ct = alphas[t] ** (0.5) * (1 - baralphas[t-1]) / (1 - baralphas[t])\n",
    "            x = c0 * x0 + ct * x\n",
    "            if t > 1:\n",
    "                # TODO: something is off here, DDPM Eq. 7 does not scale the variance by **0.5, but without it we get bad results\n",
    "                variance = (1 - baralphas[t-1]) / (1 - baralphas[t]) * betas[t]\n",
    "                variance = torch.clamp(variance, min=1e-20)\n",
    "                x += variance ** (0.5) * torch.randn(size=(nsamples, 1))  # Why **(0.5)?\n",
    "                # x += sigmas[t] * torch.randn(size=(nsamples, 1))\n",
    "                # x += (1 - baralphas[t-1]) / (1 - baralphas[t]) * betas[t] * torch.randn(size=(nsamples, 1))\n",
    "            # print(f\"Step {t} = {x[0]}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgen = sample(model, 10000)\n",
    "sns.displot(Xgen, kde=True, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2676464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
