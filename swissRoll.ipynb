{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9887c243",
   "metadata": {},
   "source": [
    "# Toy diffusion model generating data from a complex 2-d distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b88bba",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf06f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b284f76",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0311948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "x, _ = make_swiss_roll(n_samples=100000, noise=0.5)\n",
    "# Make two-dimensional to easen visualization\n",
    "x = x[:, [0, 2]]\n",
    "\n",
    "x = (x - x.mean()) / x.std()\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7472c8",
   "metadata": {},
   "source": [
    "## Prepare data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de92ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9166d03",
   "metadata": {},
   "source": [
    "## Diffusion model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e934300",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_steps = 40  # Number of steps in the diffusion process\n",
    "\n",
    "# Set noising variances betas as in Nichol and Dariwal paper (https://arxiv.org/pdf/2102.09672.pdf)\n",
    "s = 0.008\n",
    "timesteps = torch.tensor(range(0, diffusion_steps), dtype=torch.float32)\n",
    "schedule = torch.cos((timesteps / diffusion_steps + s) / (1 + s) * torch.pi / 2)**2\n",
    "\n",
    "baralphas = schedule / schedule[0]\n",
    "betas = 1 - baralphas / torch.concatenate([baralphas[0:1], baralphas[0:-1]])\n",
    "alphas = 1 - betas\n",
    "\n",
    "# Check the cumulative alphas follow the distribution recommended in the paper\n",
    "sns.lineplot(baralphas)\n",
    "plt.xlabel(\"Diffusion step\")\n",
    "plt.ylabel(r\"$\\bar{\\alpha}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad4b64",
   "metadata": {},
   "source": [
    "Function that noises a data point following the diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55680085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(Xbatch, t):\n",
    "    eps = torch.randn(size=Xbatch.shape)\n",
    "    noised = (baralphas[t] ** 0.5).repeat(1, Xbatch.shape[1]) * Xbatch + ((1 - baralphas[t]) ** 0.5).repeat(1, Xbatch.shape[1]) * eps\n",
    "    return noised, eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6282b",
   "metadata": {},
   "source": [
    "Test noising the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816df6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiselevel = 20\n",
    "\n",
    "noised, eps = noise(X, torch.full([len(X), 1], fill_value=noiselevel))\n",
    "plt.scatter(noised[:, 0], noised[:, 1], marker=\"*\", alpha=0.5)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "plt.legend([\"Noised data\", \"Original data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fa559",
   "metadata": {},
   "source": [
    "Since we know the noise we just added, we can recover the original data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1eae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = 1 / torch.sqrt(baralphas[noiselevel]) * (noised - torch.sqrt(1 - baralphas[noiselevel]) * eps)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "plt.scatter(denoised[:, 0], denoised[:, 1], marker=\"1\", alpha=0.5)\n",
    "plt.legend([\"Original data\", \"Recovered original data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392782b",
   "metadata": {},
   "source": [
    "We can also check numerically that the result is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X - denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39202a7c",
   "metadata": {},
   "source": [
    "## Diffusion network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7663e",
   "metadata": {},
   "source": [
    "Now we define a pytorch network that will learn to predict the noise component from noised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DiffusionBlock(nn.Module):\n",
    "    def __init__(self, nunits):\n",
    "        super(DiffusionBlock, self).__init__()\n",
    "        self.linear = nn.Linear(nunits, nunits)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.linear(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, nfeatures: int, nblocks: int = 2, nunits: int = 64):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        \n",
    "        self.inblock = nn.Linear(nfeatures+1, nunits)\n",
    "        self.midblocks = nn.ModuleList([DiffusionBlock(nunits) for _ in range(nblocks)])\n",
    "        self.outblock = nn.Linear(nunits, nfeatures)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        val = torch.hstack([x, t])  # Add t to inputs\n",
    "        val = self.inblock(val)\n",
    "        for midblock in self.midblocks:\n",
    "            val = midblock(val)\n",
    "        val = self.outblock(val)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b114583",
   "metadata": {},
   "source": [
    "Let's create a model with 4 inner blocks, which is enough for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModel(nfeatures=2, nblocks=4)\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e379f97",
   "metadata": {},
   "source": [
    "## Train denoising network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d045d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 2048\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=nepochs)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    epoch_loss = steps = 0\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        timesteps = torch.randint(0, diffusion_steps, size=[len(Xbatch), 1])\n",
    "        noised, eps = noise(Xbatch, timesteps)\n",
    "        predicted_noise = model(noised.to(device), timesteps.to(device))\n",
    "        loss = loss_fn(predicted_noise, eps.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss\n",
    "        steps += 1\n",
    "    print(f\"Epoch {epoch} loss = {epoch_loss / steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844512d",
   "metadata": {},
   "source": [
    "Best model: \n",
    "* DiffusionModel(nfeatures=2, nblocks=5), 40 diffusion steps, batchsize=2048, Epoch 99 loss = 0.4353588819503784\n",
    "* DiffusionModel(nfeatures=2, nblocks=2), 40 diffusion steps, batchsize=2048, Epoch 99 loss = 0.4339998960494995\n",
    "* DiffusionModel(nfeatures=2, nblocks=2), no residuals, 40 diffusion steps, batchsize=2048, Epoch 99 loss = 0.4348624050617218\n",
    "* DiffusionModel(nfeatures=2, nblocks=2), no residuals, no t replug, 40 diffusion steps, batchsize=2048, Epoch 99 loss = 0.4352072775363922\n",
    "* DiffusionModel(nfeatures=2, nblocks=2), no residuals, no t replug, no norm layers, 40 diffusion steps, batchsize=2048, Epoch 99 loss = 0.43683546781539917"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6c44f",
   "metadata": {},
   "source": [
    "## Sampling algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62562ec3",
   "metadata": {},
   "source": [
    "We will use the classic DDPM sampler, defined as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f970fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpm(model, nsamples, nfeatures):\n",
    "    \"\"\"Sampler following the Denoising Diffusion Probabilistic Models method by Ho et al (Algorithm 2)\"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(size=(nsamples, nfeatures)).to(device)\n",
    "        xt = [x]\n",
    "        for t in range(diffusion_steps-1, 0, -1):\n",
    "            predicted_noise = model(x, torch.full([nsamples, 1], t).to(device))\n",
    "            # See DDPM paper between equations 11 and 12\n",
    "            x = 1 / (alphas[t] ** 0.5) * (x - (1 - alphas[t]) / ((1-baralphas[t]) ** 0.5) * predicted_noise)\n",
    "            if t > 1:\n",
    "                # See DDPM paper section 3.2.\n",
    "                # Choosing the variance through beta_t is optimal for x_0 a normal distribution\n",
    "                variance = betas[t]\n",
    "                std = variance ** (0.5)\n",
    "                x += std * torch.randn(size=(nsamples, nfeatures)).to(device)\n",
    "            xt += [x]\n",
    "        return x, xt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f0c80",
   "metadata": {},
   "source": [
    "## Test generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b74223",
   "metadata": {},
   "source": [
    "Let's generate 10K samples of the learned distribution using the diffusion model we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgen, Xgen_hist = sample_ddpm(model, 10000, 2)\n",
    "Xgen = Xgen.cpu()\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "plt.scatter(Xgen[:, 0], Xgen[:, 1], marker=\"1\", alpha=0.5)\n",
    "plt.legend([\"Original data\", \"Generated data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e61272",
   "metadata": {},
   "source": [
    "We can also create an animation of the denoising process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "def draw_frame(i):\n",
    "    plt.clf()\n",
    "    Xvis = Xgen_hist[i].cpu()\n",
    "    fig = plt.scatter(Xvis[:, 0], Xvis[:, 1], marker=\"1\", animated=True)\n",
    "    plt.xlim([-2.5, 2.5])\n",
    "    plt.ylim([-2.5, 2.5])\n",
    "    return fig,\n",
    "\n",
    "fig = plt.figure()\n",
    "anim = animation.FuncAnimation(fig, draw_frame, frames=40, interval=20, blit=True)\n",
    "anim.save('swissroll_generation.mp4', fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "<video width=\"80%\" controls>\n",
    "      <source src=\"swissroll_generation.mp4\" type=\"video/mp4\">\n",
    "</video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459722b",
   "metadata": {},
   "source": [
    "## Extras: alternative sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2de618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpm_x0(model, nsamples, nfeatures):\n",
    "    \"\"\"Sampler that uses the equations in DDPM paper to predict x0, then use that to predict x_{t-1}\n",
    "    \n",
    "    This is how DDPM is implemented in HuggingFace Diffusers, to allow working with models that predict\n",
    "    x0 instead of the noise. It is also how we explain it in the Mixture of Diffusers paper.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(size=(nsamples, nfeatures)).to(device)\n",
    "        for t in range(diffusion_steps-1, 0, -1):\n",
    "            predicted_noise = model(x, torch.full([nsamples, 1], t).to(device))\n",
    "            # Predict original sample using DDPM Eq. 15\n",
    "            x0 = (x - (1 - baralphas[t]) ** (0.5) * predicted_noise) / baralphas[t] ** (0.5)\n",
    "            # Predict previous sample using DDPM Eq. 7\n",
    "            c0 = (baralphas[t-1] ** (0.5) * betas[t]) / (1 - baralphas[t])\n",
    "            ct = alphas[t] ** (0.5) * (1 - baralphas[t-1]) / (1 - baralphas[t])\n",
    "            x = c0 * x0 + ct * x\n",
    "            # Add noise\n",
    "            if t > 1:\n",
    "                # Instead of variance = betas[t] the Stable Diffusion implementation uses this expression\n",
    "                variance = (1 - baralphas[t-1]) / (1 - baralphas[t]) * betas[t]\n",
    "                variance = torch.clamp(variance, min=1e-20)\n",
    "                std = variance ** (0.5)\n",
    "                x += std * torch.randn(size=(nsamples, nfeatures)).to(device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgen = sample_ddpm_x0(model, 10000, 2).cpu()\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "plt.scatter(Xgen[:, 0], Xgen[:, 1], marker=\"1\", alpha=0.5)\n",
    "plt.legend([\"Original data\", \"Generated data\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
